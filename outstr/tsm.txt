Recognizer2D(
  23.52 M, 100.000% Params, 65.918 GFLOPs, 100.000% FLOPs, 
  (backbone): ResNetTSM(
    23.508 M, 99.948% Params, 65.916 GFLOPs, 99.997% FLOPs, 
    (conv1): ConvModule(
      0.01 M, 0.041% Params, 1.927 GFLOPs, 2.923% FLOPs, 
      (conv): Conv2d(0.009 M, 0.040% Params, 1.888 GFLOPs, 2.864% FLOPs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.026 GFLOPs, 0.039% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(0.0 M, 0.000% Params, 0.013 GFLOPs, 0.019% FLOPs, inplace=True)
    )
    (maxpool): MaxPool2d(0.0 M, 0.000% Params, 0.013 GFLOPs, 0.019% FLOPs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      0.216 M, 0.918% Params, 10.886 GFLOPs, 16.515% FLOPs, 
      (0): Bottleneck(
        0.075 M, 0.319% Params, 3.783 GFLOPs, 5.739% FLOPs, 
        (conv1): ConvModule(
          0.004 M, 0.018% Params, 0.215 GFLOPs, 0.326% FLOPs, 
          (conv): TemporalShift(
            0.004 M, 0.017% Params, 0.206 GFLOPs, 0.312% FLOPs, 
            (net): Conv2d(0.004 M, 0.017% Params, 0.206 GFLOPs, 0.312% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.006 GFLOPs, 0.010% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.037 M, 0.157% Params, 1.859 GFLOPs, 2.821% FLOPs, 
          (conv): Conv2d(0.037 M, 0.157% Params, 1.85 GFLOPs, 2.806% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.006 GFLOPs, 0.010% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.017 M, 0.072% Params, 0.848 GFLOPs, 1.286% FLOPs, 
          (conv): Conv2d(0.016 M, 0.070% Params, 0.822 GFLOPs, 1.247% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.026 GFLOPs, 0.039% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.013 GFLOPs, 0.019% FLOPs, inplace=True)
        (downsample): ConvModule(
          0.017 M, 0.072% Params, 0.848 GFLOPs, 1.286% FLOPs, 
          (conv): Conv2d(0.016 M, 0.070% Params, 0.822 GFLOPs, 1.247% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.026 GFLOPs, 0.039% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        0.07 M, 0.299% Params, 3.552 GFLOPs, 5.388% FLOPs, 
        (conv1): ConvModule(
          0.017 M, 0.070% Params, 0.832 GFLOPs, 1.262% FLOPs, 
          (conv): TemporalShift(
            0.016 M, 0.070% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(0.016 M, 0.070% Params, 0.822 GFLOPs, 1.247% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.006 GFLOPs, 0.010% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.037 M, 0.157% Params, 1.859 GFLOPs, 2.821% FLOPs, 
          (conv): Conv2d(0.037 M, 0.157% Params, 1.85 GFLOPs, 2.806% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.006 GFLOPs, 0.010% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.017 M, 0.072% Params, 0.848 GFLOPs, 1.286% FLOPs, 
          (conv): Conv2d(0.016 M, 0.070% Params, 0.822 GFLOPs, 1.247% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.026 GFLOPs, 0.039% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.013 GFLOPs, 0.019% FLOPs, inplace=True)
      )
      (2): Bottleneck(
        0.07 M, 0.299% Params, 3.552 GFLOPs, 5.388% FLOPs, 
        (conv1): ConvModule(
          0.017 M, 0.070% Params, 0.832 GFLOPs, 1.262% FLOPs, 
          (conv): TemporalShift(
            0.016 M, 0.070% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(0.016 M, 0.070% Params, 0.822 GFLOPs, 1.247% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.006 GFLOPs, 0.010% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.037 M, 0.157% Params, 1.859 GFLOPs, 2.821% FLOPs, 
          (conv): Conv2d(0.037 M, 0.157% Params, 1.85 GFLOPs, 2.806% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.006 GFLOPs, 0.010% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.017 M, 0.072% Params, 0.848 GFLOPs, 1.286% FLOPs, 
          (conv): Conv2d(0.016 M, 0.070% Params, 0.822 GFLOPs, 1.247% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.026 GFLOPs, 0.039% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.013 GFLOPs, 0.019% FLOPs, inplace=True)
      )
    )
    (layer2): Sequential(
      1.22 M, 5.185% Params, 16.585 GFLOPs, 25.159% FLOPs, 
      (0): Bottleneck(
        0.379 M, 1.613% Params, 6.016 GFLOPs, 9.127% FLOPs, 
        (conv1): ConvModule(
          0.033 M, 0.140% Params, 1.663 GFLOPs, 2.523% FLOPs, 
          (conv): TemporalShift(
            0.033 M, 0.139% Params, 1.644 GFLOPs, 2.494% FLOPs, 
            (net): Conv2d(0.033 M, 0.139% Params, 1.644 GFLOPs, 2.494% FLOPs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.013 GFLOPs, 0.019% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.010% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.148 M, 0.628% Params, 1.855 GFLOPs, 2.813% FLOPs, 
          (conv): Conv2d(0.147 M, 0.627% Params, 1.85 GFLOPs, 2.806% FLOPs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.003 GFLOPs, 0.005% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.067 M, 0.283% Params, 0.835 GFLOPs, 1.267% FLOPs, 
          (conv): Conv2d(0.066 M, 0.279% Params, 0.822 GFLOPs, 1.247% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.013 GFLOPs, 0.019% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.010% FLOPs, inplace=True)
        (downsample): ConvModule(
          0.132 M, 0.562% Params, 1.657 GFLOPs, 2.514% FLOPs, 
          (conv): Conv2d(0.131 M, 0.557% Params, 1.644 GFLOPs, 2.494% FLOPs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.013 GFLOPs, 0.019% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        0.28 M, 1.191% Params, 3.523 GFLOPs, 5.344% FLOPs, 
        (conv1): ConvModule(
          0.066 M, 0.280% Params, 0.827 GFLOPs, 1.254% FLOPs, 
          (conv): TemporalShift(
            0.066 M, 0.279% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(0.066 M, 0.279% Params, 0.822 GFLOPs, 1.247% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.003 GFLOPs, 0.005% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.148 M, 0.628% Params, 1.855 GFLOPs, 2.813% FLOPs, 
          (conv): Conv2d(0.147 M, 0.627% Params, 1.85 GFLOPs, 2.806% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.003 GFLOPs, 0.005% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.067 M, 0.283% Params, 0.835 GFLOPs, 1.267% FLOPs, 
          (conv): Conv2d(0.066 M, 0.279% Params, 0.822 GFLOPs, 1.247% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.013 GFLOPs, 0.019% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.010% FLOPs, inplace=True)
      )
      (2): Bottleneck(
        0.28 M, 1.191% Params, 3.523 GFLOPs, 5.344% FLOPs, 
        (conv1): ConvModule(
          0.066 M, 0.280% Params, 0.827 GFLOPs, 1.254% FLOPs, 
          (conv): TemporalShift(
            0.066 M, 0.279% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(0.066 M, 0.279% Params, 0.822 GFLOPs, 1.247% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.003 GFLOPs, 0.005% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.148 M, 0.628% Params, 1.855 GFLOPs, 2.813% FLOPs, 
          (conv): Conv2d(0.147 M, 0.627% Params, 1.85 GFLOPs, 2.806% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.003 GFLOPs, 0.005% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.067 M, 0.283% Params, 0.835 GFLOPs, 1.267% FLOPs, 
          (conv): Conv2d(0.066 M, 0.279% Params, 0.822 GFLOPs, 1.247% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.013 GFLOPs, 0.019% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.010% FLOPs, inplace=True)
      )
      (3): Bottleneck(
        0.28 M, 1.191% Params, 3.523 GFLOPs, 5.344% FLOPs, 
        (conv1): ConvModule(
          0.066 M, 0.280% Params, 0.827 GFLOPs, 1.254% FLOPs, 
          (conv): TemporalShift(
            0.066 M, 0.279% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(0.066 M, 0.279% Params, 0.822 GFLOPs, 1.247% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.003 GFLOPs, 0.005% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.148 M, 0.628% Params, 1.855 GFLOPs, 2.813% FLOPs, 
          (conv): Conv2d(0.147 M, 0.627% Params, 1.85 GFLOPs, 2.806% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.0 M, 0.001% Params, 0.003 GFLOPs, 0.005% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.067 M, 0.283% Params, 0.835 GFLOPs, 1.267% FLOPs, 
          (conv): Conv2d(0.066 M, 0.279% Params, 0.822 GFLOPs, 1.247% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.013 GFLOPs, 0.019% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.006 GFLOPs, 0.010% FLOPs, inplace=True)
      )
    )
    (layer3): Sequential(
      7.098 M, 30.180% Params, 23.53 GFLOPs, 35.695% FLOPs, 
      (0): Bottleneck(
        1.512 M, 6.430% Params, 5.988 GFLOPs, 9.084% FLOPs, 
        (conv1): ConvModule(
          0.132 M, 0.559% Params, 1.654 GFLOPs, 2.509% FLOPs, 
          (conv): TemporalShift(
            0.131 M, 0.557% Params, 1.644 GFLOPs, 2.494% FLOPs, 
            (net): Conv2d(0.131 M, 0.557% Params, 1.644 GFLOPs, 2.494% FLOPs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.006 GFLOPs, 0.010% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.59 M, 2.510% Params, 1.852 GFLOPs, 2.810% FLOPs, 
          (conv): Conv2d(0.59 M, 2.508% Params, 1.85 GFLOPs, 2.806% FLOPs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.264 M, 1.123% Params, 0.829 GFLOPs, 1.257% FLOPs, 
          (conv): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.002 M, 0.009% Params, 0.006 GFLOPs, 0.010% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
        (downsample): ConvModule(
          0.526 M, 2.238% Params, 1.651 GFLOPs, 2.504% FLOPs, 
          (conv): Conv2d(0.524 M, 2.229% Params, 1.644 GFLOPs, 2.494% FLOPs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (bn): BatchNorm2d(0.002 M, 0.009% Params, 0.006 GFLOPs, 0.010% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        1.117 M, 4.750% Params, 3.508 GFLOPs, 5.322% FLOPs, 
        (conv1): ConvModule(
          0.263 M, 1.117% Params, 0.824 GFLOPs, 1.251% FLOPs, 
          (conv): TemporalShift(
            0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.59 M, 2.510% Params, 1.852 GFLOPs, 2.810% FLOPs, 
          (conv): Conv2d(0.59 M, 2.508% Params, 1.85 GFLOPs, 2.806% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.264 M, 1.123% Params, 0.829 GFLOPs, 1.257% FLOPs, 
          (conv): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.002 M, 0.009% Params, 0.006 GFLOPs, 0.010% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
      )
      (2): Bottleneck(
        1.117 M, 4.750% Params, 3.508 GFLOPs, 5.322% FLOPs, 
        (conv1): ConvModule(
          0.263 M, 1.117% Params, 0.824 GFLOPs, 1.251% FLOPs, 
          (conv): TemporalShift(
            0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.59 M, 2.510% Params, 1.852 GFLOPs, 2.810% FLOPs, 
          (conv): Conv2d(0.59 M, 2.508% Params, 1.85 GFLOPs, 2.806% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.264 M, 1.123% Params, 0.829 GFLOPs, 1.257% FLOPs, 
          (conv): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.002 M, 0.009% Params, 0.006 GFLOPs, 0.010% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
      )
      (3): Bottleneck(
        1.117 M, 4.750% Params, 3.508 GFLOPs, 5.322% FLOPs, 
        (conv1): ConvModule(
          0.263 M, 1.117% Params, 0.824 GFLOPs, 1.251% FLOPs, 
          (conv): TemporalShift(
            0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.59 M, 2.510% Params, 1.852 GFLOPs, 2.810% FLOPs, 
          (conv): Conv2d(0.59 M, 2.508% Params, 1.85 GFLOPs, 2.806% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.264 M, 1.123% Params, 0.829 GFLOPs, 1.257% FLOPs, 
          (conv): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.002 M, 0.009% Params, 0.006 GFLOPs, 0.010% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
      )
      (4): Bottleneck(
        1.117 M, 4.750% Params, 3.508 GFLOPs, 5.322% FLOPs, 
        (conv1): ConvModule(
          0.263 M, 1.117% Params, 0.824 GFLOPs, 1.251% FLOPs, 
          (conv): TemporalShift(
            0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.59 M, 2.510% Params, 1.852 GFLOPs, 2.810% FLOPs, 
          (conv): Conv2d(0.59 M, 2.508% Params, 1.85 GFLOPs, 2.806% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.264 M, 1.123% Params, 0.829 GFLOPs, 1.257% FLOPs, 
          (conv): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.002 M, 0.009% Params, 0.006 GFLOPs, 0.010% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
      )
      (5): Bottleneck(
        1.117 M, 4.750% Params, 3.508 GFLOPs, 5.322% FLOPs, 
        (conv1): ConvModule(
          0.263 M, 1.117% Params, 0.824 GFLOPs, 1.251% FLOPs, 
          (conv): TemporalShift(
            0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          0.59 M, 2.510% Params, 1.852 GFLOPs, 2.810% FLOPs, 
          (conv): Conv2d(0.59 M, 2.508% Params, 1.85 GFLOPs, 2.806% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.002% Params, 0.002 GFLOPs, 0.002% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.001 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          0.264 M, 1.123% Params, 0.829 GFLOPs, 1.257% FLOPs, 
          (conv): Conv2d(0.262 M, 1.115% Params, 0.822 GFLOPs, 1.247% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.002 M, 0.009% Params, 0.006 GFLOPs, 0.010% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.003 GFLOPs, 0.005% FLOPs, inplace=True)
      )
    )
    (layer4): Sequential(
      14.965 M, 63.625% Params, 12.976 GFLOPs, 19.685% FLOPs, 
      (0): Bottleneck(
        6.04 M, 25.678% Params, 5.974 GFLOPs, 9.063% FLOPs, 
        (conv1): ConvModule(
          0.525 M, 2.233% Params, 1.649 GFLOPs, 2.502% FLOPs, 
          (conv): TemporalShift(
            0.524 M, 2.229% Params, 1.644 GFLOPs, 2.494% FLOPs, 
            (net): Conv2d(0.524 M, 2.229% Params, 1.644 GFLOPs, 2.494% FLOPs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.003 GFLOPs, 0.005% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          2.36 M, 10.035% Params, 1.851 GFLOPs, 2.808% FLOPs, 
          (conv): Conv2d(2.359 M, 10.031% Params, 1.85 GFLOPs, 2.806% FLOPs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.001 GFLOPs, 0.001% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          1.053 M, 4.476% Params, 0.825 GFLOPs, 1.252% FLOPs, 
          (conv): Conv2d(1.049 M, 4.458% Params, 0.822 GFLOPs, 1.247% FLOPs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.004 M, 0.017% Params, 0.003 GFLOPs, 0.005% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
        (downsample): ConvModule(
          2.101 M, 8.934% Params, 1.647 GFLOPs, 2.499% FLOPs, 
          (conv): Conv2d(2.097 M, 8.916% Params, 1.644 GFLOPs, 2.494% FLOPs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (bn): BatchNorm2d(0.004 M, 0.017% Params, 0.003 GFLOPs, 0.005% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        4.463 M, 18.973% Params, 3.501 GFLOPs, 5.311% FLOPs, 
        (conv1): ConvModule(
          1.05 M, 4.463% Params, 0.823 GFLOPs, 1.249% FLOPs, 
          (conv): TemporalShift(
            1.049 M, 4.458% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(1.049 M, 4.458% Params, 0.822 GFLOPs, 1.247% FLOPs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.001 GFLOPs, 0.001% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          2.36 M, 10.035% Params, 1.851 GFLOPs, 2.808% FLOPs, 
          (conv): Conv2d(2.359 M, 10.031% Params, 1.85 GFLOPs, 2.806% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.001 GFLOPs, 0.001% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          1.053 M, 4.476% Params, 0.825 GFLOPs, 1.252% FLOPs, 
          (conv): Conv2d(1.049 M, 4.458% Params, 0.822 GFLOPs, 1.247% FLOPs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.004 M, 0.017% Params, 0.003 GFLOPs, 0.005% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
      )
      (2): Bottleneck(
        4.463 M, 18.973% Params, 3.501 GFLOPs, 5.311% FLOPs, 
        (conv1): ConvModule(
          1.05 M, 4.463% Params, 0.823 GFLOPs, 1.249% FLOPs, 
          (conv): TemporalShift(
            1.049 M, 4.458% Params, 0.822 GFLOPs, 1.247% FLOPs, 
            (net): Conv2d(1.049 M, 4.458% Params, 0.822 GFLOPs, 1.247% FLOPs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.001 GFLOPs, 0.001% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv2): ConvModule(
          2.36 M, 10.035% Params, 1.851 GFLOPs, 2.808% FLOPs, 
          (conv): Conv2d(2.359 M, 10.031% Params, 1.85 GFLOPs, 2.806% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(0.001 M, 0.004% Params, 0.001 GFLOPs, 0.001% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.001% FLOPs, inplace=True)
        )
        (conv3): ConvModule(
          1.053 M, 4.476% Params, 0.825 GFLOPs, 1.252% FLOPs, 
          (conv): Conv2d(1.049 M, 4.458% Params, 0.822 GFLOPs, 1.247% FLOPs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(0.004 M, 0.017% Params, 0.003 GFLOPs, 0.005% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, inplace=True)
      )
    )
  )
  (cls_head): TSMHead(
    0.012 M, 0.052% Params, 0.002 GFLOPs, 0.003% FLOPs, 
    (loss_cls): CrossEntropyLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )
    (consensus): AvgConsensus(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )
    (dropout): Dropout(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, p=0.5, inplace=False)
    (fc_cls): Linear(0.012 M, 0.052% Params, 0.0 GFLOPs, 0.000% FLOPs, in_features=2048, out_features=6, bias=True)
    (avg_pool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.002% FLOPs, output_size=1)
  )
)
==============================
Input shape: (16, 3, 224, 224)
Flops: 65.92 GFLOPs
Params: 23.52 M
==============================

